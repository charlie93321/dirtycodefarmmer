package com.hbgj.test

import org.apache.spark.{SparkConf, SparkContext}
import org.apache.spark.sql.{DataFrame, SaveMode}
import org.apache.spark.sql.hive.HiveContext

/**
  *
  * 找出用户的居住城市 ------------> 常驻城市
  *
  * 查询一年的数据 , 默认 一周调度一次
  *
  *
  * 手机归属地                 权重           0.1
  * 出行行程                   权重           0.6
  * 活跃城市(经纬度表)          权重           0.2
  * 身份证地址                  权重           0.1
  *
  *
  *
  *
  */
object TestResidentCity {

 //手机归属地                 权重           0.1
  private val  PHONE_WEIGHT:Double=0.1
  //出行行程                   权重           0.6
  private val  TRAVEL_WEIGHT:Double=0.6
  //活跃城市(经纬度表)          权重           0.2
  private val  ACTIVE_CITY_WEIGHT:Double=0.2
  //身份证地址                  权重           0.1
  private val  CARE_ID_WEIGHT:Double=0.1

  private  var hsc:HiveContext=null

  private  var   S_AIRLINE_ORDER_DATE="2018-07-01"

  private  var   AREABY_LATLNT_EVENT_DATE="2018-07-01"

  private var     STATICS_DATE="201808"


/**
  *手机归属地                 权重           0.1
  *
  * s_airline_order   s_airline_order （主订单表）：default  航班订单表
  * user_id          |   手机id
  * order_id         |   订单id
  * orderstatue      |   订单状态
  * invoice_address  |   发票寄送地址
  * contact_phone	   |	 联系电话
  *
  * 订单状态： 0临时 1预订成功 11预订失败 12订单作废 2未支付 21支付待确认
  * 3支付成功 31支付失败 4待出票 41抢票中 5出票成功 51出票失败 52客票已使用
  * 53行程单已邮寄 6退票处理中 61已退票，待退款 62退款处理中 63已退票，已退款
  * 64退票失败 65退款失败 7改升处理中 71已改升 72改升支付待确认 73改升支付成功 74部分已改升 75全部已改升
  *
  * ['5'(出票成功), '52'(客票已使用), '53'(行程单已邮寄), '71'(已改升), '73'(改升支付成功), '74'(部分已改升), '75'(全部已改升)]
  *
  *s_airline_order_detail  航班订单详情表
  * order_id        |      订单id
  * passenger_uid   |      身份证号或护照(id_card|passport)
  * dep_time        |      出发时间
  * dep_city_name   |      出发城市
  * arr_city_name   |      到达城市
  *
  *
  *
  * s_user_info
  * user_id    |  手机id
  * passport   |   护照
  * id_card    |   身份证
  *
  * 订票者 的所有行程  (其中已剔除  帮别人订票的别人的行程 )
  */


  /**
    * 手机归属和出行权重可以合并在一起查询
    */
  def   contactPhoneWeight(): Unit ={
    val phone_sql1=
      s"""
        | select u.user_id,
        |        o.contact_phone,
        |        d.dep_city_name,
        |        d.arr_city_name
        |   from ( select * from s_airline_order_detail where dt >= $S_AIRLINE_ORDER_DATE) d
        |   join ( select * from s_airline_order        where dt >= $S_AIRLINE_ORDER_DATE) o
        |     on ( d.order_id = o.order_id and
        |        o.orderstatue IN ('5', '52', '53', '71', '73', '74', '75'))
        |   join s_user_info u
        |     on (u.user_id = o.user_id and
        |        (u.passport = d.passenger_uid OR u.id_card = d.passenger_uid))
      """.stripMargin
      val phone_travel_df:DataFrame = hsc.sql(phone_sql1)
      phone_travel_df.registerTempTable("temp_phone_travel_table")
    /**
      *default.phone_location  手机归属地查询
      * 手机归属地                 权重           0.1
      */
    val phone_sql2=
      s"""
        |
        |select u.user_id, pl.city, u.rate*$PHONE_WEIGHT
        |  from (select a.user_id,
        |               substr(a.contact_phone, 0, 7) as phone_prefix,
        |               a.cnt / t.allcnt as rate
        |          from (select user_id, contact_phone, count(1) cnt
        |                  from temp_phone_travel_table
        |                 group by user_id, contact_phone) a
        |          join (select user_id, count(1) as allcnt
        |                 from temp_phone_travel_table
        |                group by user_id) t
        |            on a.user_id = t.user_id) u
        |  join default.phone_location pl
        |    on u.phone_prefix = pl.phone_number
      """.stripMargin
     val phone_df:DataFrame = hsc.sql(phone_sql2)
    phone_df.registerTempTable("temp_phone_weight_table")
    //---del---
   // phone_df.rdd.saveAsTextFile("D:\\zxy\\tempdir\\phone_df")
  }
  /**
    * 出行   权重
    * 出行行程                   权重           0.6
    * phone_travel_df.registerTempTable("temp_phone_travel_table")
    */
  def  travelWeight(): Unit ={

    val travel_sql=
      s"""
        |select t2.user_id,
        |       t2.city,
        |       (t2.cnum / (sum(t2.cnum) over(partition by t2.user_id))) * $TRAVEL_WEIGHT rate
        |  from (select t1.user_id, t1.city, count(1) cnum
        |          from (select user_id, dep_city_name city
        |                  from temp_phone_travel_table
        |                union all
        |                select user_id, arr_city_name city
        |                  from temp_phone_travel_table ) t1
        |         group by t1.user_id, t1.city) t2
        |
      """.stripMargin

    val travel_df:DataFrame = hsc.sql(travel_sql)

    travel_df.registerTempTable("temp_travel_weight_table")


    //---del---
   // travel_df.rdd.saveAsTextFile("D:\\zxy\\tempdir\\travel_df")

    hsc.dropTempTable("temp_phone_travel_table")

  }


  /**
    *
    * 活跃城市(经纬度表)          权重           0.2
    *
    */

  def  activeCityWeightByLatlnt(): Unit ={

     val active_sql=
       s"""
         |select t2.user_id,
         |       t2.city,
         |       (t2.cnum / ( sum(t2.cnum) over(partition by t2.user_id))) * $ACTIVE_CITY_WEIGHT rate
         |  from (select t1.user_id, t1.city, count(1) cnum
         |          from (select phoneid user_id, city
         |                  from sp_class.areaby_latlnt
         |                 where event_date>=$AREABY_LATLNT_EVENT_DATE  and   phoneid != 'NULL') t1
         |         group by t1.user_id, t1.city) t2
       """.stripMargin

    val active_city_df:DataFrame = hsc.sql(active_sql)

    active_city_df.registerTempTable("temp_active_city_weight_table")

    //---del---
   // active_city_df.rdd.saveAsTextFile("D:\\zxy\\tempdir\\active_city_df")

  }

  /**
    *  身份证地址                  权重           0.1
    *  全量数据
    *
    */
  def  cardIdWeight(): Unit ={

    val card_sql=
      s"""
        |select t1.user_id, t1.born_city city, $CARE_ID_WEIGHT rate
        |  from s_user_info t1
      """.stripMargin

    val id_card_df:DataFrame = hsc.sql(card_sql)

    id_card_df.registerTempTable("temp_id_card_weight_table")

    //---del---
   // id_card_df.rdd.saveAsTextFile("D:\\zxy\\tempdir\\id_card_df")
  }

  def combineToResult(): Unit = {

    val combine_sql=
      """
        |select t2.user_id,
        |       t2.city,
        |       row_number() over(partition by t2.user_id order by t2.all_rate desc) rk
        |  from (select t1.user_id, t1.city, sum(t1.rate) all_rate
        |          from (select *
        |                  from temp_id_card_weight_table
        |                union all
        |                select *
        |                  from temp_active_city_weight_table
        |                union all
        |                select *
        |                  from temp_travel_weight_table
        |                union all
        |                select * from temp_phone_weight_table) t1
        |         group by t1.user_id, t1.city) t2
      """.stripMargin

    val combine_df:DataFrame = hsc.sql(combine_sql)
    combine_df.write.format("orc").mode(SaveMode.Append).saveAsTable(s"resident_city_$STATICS_DATE")
  }

  def main(args: Array[String]): Unit = {
    val conf=new  SparkConf()
   // conf.setMaster("local[18]").setAppName("test-1")
    val sc=new SparkContext(conf)
    hsc=new HiveContext(sc)
    contactPhoneWeight()
    travelWeight()
    activeCityWeightByLatlnt()
    cardIdWeight()
    combineToResult()
    sc.stop()
  }
}



